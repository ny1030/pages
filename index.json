[{"content":"概要 ApacheやNginx、ELBのアクセスログの集計などをする時に以下のような変換を行う必要がある。\nInput:\ntimestamp,backend_processing_time_msec,alb_status_code,backend_status_code,target_status_code_list,method,URL 2021-12-01T03:50:00.115676Z,182,201,201,201,POST,https://api.test.io:443/service1/v2/jp/cart/7219b08ec8464865a6020bb6025cd641/details 2021-12-01T03:50:20.597508Z,67,200,200,200,GET,https://api.test.io:443/service2/v2/jp/history/0130050002112010350-8052922 2021-12-01T03:50:20.613452Z,145,200,200,200,GET,https://api.test.io:443/service2/v2/jp/history?display_results=5\u0026amp;search_page=1 2021-12-01T03:50:20.894114Z,22,200,200,200,GET,https://api.test.io:443/service2/v2/jp/history/0130050002112010350-8052921 2021-12-01T03:51:45.903017Z,8,404,404,404,DELETE,https://api.test.io:443/service3/v1/jp/reserve/7041b995fa1b4c8b99543acc50c60865 2021-12-01T03:54:41.598315Z,20,200,200,200,GET,https://api.test.io:443/service3/v1/jp/stocks?code_list=11111111%22222222%33333333 2021-12-01T03:54:56.672346Z,165,200,200,200,GET,https://api.test.io:443/service4/v1/jp/pay/accesstoken?device_id=AAAAA-BBBB-CCC ⬇️ URLの正規化（≒変換, 名寄せ）\nOutput:\ntimestamp,backend_processing_time_msec,alb_status_code,backend_status_code,method,URL 2021-12-01T03:50:00.115676Z,182.0,201,201,POST,https://api.test.io:443/service1/v2/jp/cart/{cart_no}/details 2021-12-01T03:50:20.597508Z,67.0,200,200,GET,https://api.test.io:443/service2/v2/jp/history/{order_no} 2021-12-01T03:50:20.613452Z,145.0,200,200,GET,https://api.test.io:443/service2/v2/jp/history 2021-12-01T03:50:20.894114Z,22.0,200,200,GET,https://api.test.io:443/service2/v2/jp/history/{order_no} 2021-12-01T03:51:45.903017Z,8.0,404,404,DELETE,https://api.test.io:443/service3/v1/jp/reserve/{cart_no} 2021-12-01T03:54:41.598315Z,20.0,200,200,GET,https://api.test.io:443/service3/v1/jp/stocks 2021-12-01T03:54:56.672346Z,165.0,200,200,GET,https://api.test.io:443/service4/v1/jp/pay/accesstoken 上記のような変換を行うことで、APIのEndpointごとにコール回数やレスポンス時間など統計処理をPandasなどを行うことができる。\nコード 概要で説明したような事を実現するために、以下のコードを作成。\n1. URLの変換パターンを定義した設定ファイル（JSON）  置換のパターンはAPIの定義書などを参考に記述するのが良い（ない場合はアクセスログからリバースするしかない\u0026hellip;）  { \t\u0026#34;^(.*)/history/[0-9]{12,19}-[0-9]{5,7}\u0026#34;: \u0026#34;\\\\1/history/{order_no}\u0026#34;, \t\u0026#34;^(.*)(cart|reserve)/[0-9a-z]{32}\u0026#34;: \u0026#34;\\\\1\\\\2/{cart_no}\u0026#34; } 2. inputしたCSVからURLの変換処理を行うスクリプト（Python）  タイトル詐欺になるが、クエリパラメータに関する置換はルールが単純なのでJSONでは定義せず、こちらのスクリプトで定義・処理している（# REMOVE QUERY PARAMETERのセクション）。  import pandas as pd import json  input_filename = \u0026#39;./input.csv\u0026#39; output_filename = \u0026#39;./output.csv\u0026#39;  input_csv = pd.read_csv(  input_filename,  sep=\u0026#39;,\u0026#39;,  usecols=lambda x: x in [\u0026#39;timestamp\u0026#39;,\u0026#39;alb_status_code\u0026#39;, \u0026#39;backend_status_code\u0026#39;, \u0026#39;method\u0026#39;, \u0026#39;URL\u0026#39;, \u0026#39;backend_processing_time_msec\u0026#39;],  index_col=\u0026#39;timestamp\u0026#39;,  dtype={\u0026#39;timestamp\u0026#39;: str, \u0026#39;alb_status_code\u0026#39;: str, \u0026#39;backend_status_code\u0026#39;: str, \u0026#39;method\u0026#39;: str, \u0026#39;URL\u0026#39;: str, \u0026#39;backend_processing_time_msec\u0026#39;: \u0026#39;float16\u0026#39;} )  # REMOVE QUERY PARAMETER input_csv = pd.concat([input_csv, input_csv[\u0026#34;URL\u0026#34;].str.extract(r\u0026#39;([^\\?]+).*\u0026#39;, expand=True)], axis=1, ignore_index=False) input_csv = input_csv.drop(columns=[\u0026#34;URL\u0026#34;]) input_csv.rename(columns={0: \u0026#39;URL\u0026#39;}, inplace=True)  # REPLACE ID IN URL TEXT FOR AGGREGATION with open(\u0026#39;./replace-pattern.json\u0026#39;) as f:  dct = json.load(f) input_csv[\u0026#34;URL\u0026#34;] = input_csv[\u0026#34;URL\u0026#34;].replace(dct, regex=True)  # Output to CSV input_csv.to_csv(output_filename, header=True, index=True) exit python test.py 実行することで概要通りの csvに変換されることを確認。\n","permalink":"https://ny1030.github.io/pages/posts/engineering/json%E3%81%A7%E5%AE%9A%E7%BE%A9%E3%81%97%E3%81%9Furl%E3%81%AE%E7%BD%AE%E6%8F%9B%E3%83%AB%E3%83%BC%E3%83%AB%E3%82%92python%E3%81%A7%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B/","summary":"概要 ApacheやNginx、ELBのアクセスログの集計などをする時に以下のような変換を行う必要がある。\nInput:\ntimestamp,backend_processing_time_msec,alb_status_code,backend_status_code,target_status_code_list,method,URL 2021-12-01T03:50:00.115676Z,182,201,201,201,POST,https://api.test.io:443/service1/v2/jp/cart/7219b08ec8464865a6020bb6025cd641/details 2021-12-01T03:50:20.597508Z,67,200,200,200,GET,https://api.test.io:443/service2/v2/jp/history/0130050002112010350-8052922 2021-12-01T03:50:20.613452Z,145,200,200,200,GET,https://api.test.io:443/service2/v2/jp/history?display_results=5\u0026amp;search_page=1 2021-12-01T03:50:20.894114Z,22,200,200,200,GET,https://api.test.io:443/service2/v2/jp/history/0130050002112010350-8052921 2021-12-01T03:51:45.903017Z,8,404,404,404,DELETE,https://api.test.io:443/service3/v1/jp/reserve/7041b995fa1b4c8b99543acc50c60865 2021-12-01T03:54:41.598315Z,20,200,200,200,GET,https://api.test.io:443/service3/v1/jp/stocks?code_list=11111111%22222222%33333333 2021-12-01T03:54:56.672346Z,165,200,200,200,GET,https://api.test.io:443/service4/v1/jp/pay/accesstoken?device_id=AAAAA-BBBB-CCC ⬇️ URLの正規化（≒変換, 名寄せ）\nOutput:\ntimestamp,backend_processing_time_msec,alb_status_code,backend_status_code,method,URL 2021-12-01T03:50:00.115676Z,182.0,201,201,POST,https://api.test.io:443/service1/v2/jp/cart/{cart_no}/details 2021-12-01T03:50:20.597508Z,67.0,200,200,GET,https://api.test.io:443/service2/v2/jp/history/{order_no} 2021-12-01T03:50:20.613452Z,145.0,200,200,GET,https://api.test.io:443/service2/v2/jp/history 2021-12-01T03:50:20.894114Z,22.0,200,200,GET,https://api.test.io:443/service2/v2/jp/history/{order_no} 2021-12-01T03:51:45.903017Z,8.0,404,404,DELETE,https://api.test.io:443/service3/v1/jp/reserve/{cart_no} 2021-12-01T03:54:41.598315Z,20.0,200,200,GET,https://api.test.io:443/service3/v1/jp/stocks 2021-12-01T03:54:56.672346Z,165.0,200,200,GET,https://api.test.io:443/service4/v1/jp/pay/accesstoken 上記のような変換を行うことで、APIのEndpointごとにコール回数やレスポンス時間など統計処理をPandasなどを行うことができる。\nコード 概要で説明したような事を実現するために、以下のコードを作成。\n1. URLの変換パターンを定義した設定ファイル（JSON）  置換のパターンはAPIの定義書などを参考に記述するのが良い（ない場合はアクセスログからリバースするしかない\u0026hellip;）  { \t\u0026#34;^(.*)/history/[0-9]{12,19}-[0-9]{5,7}\u0026#34;: \u0026#34;\\\\1/history/{order_no}\u0026#34;, \t\u0026#34;^(.*)(cart|reserve)/[0-9a-z]{32}\u0026#34;: \u0026#34;\\\\1\\\\2/{cart_no}\u0026#34; } 2. inputしたCSVからURLの変換処理を行うスクリプト（Python）  タイトル詐欺になるが、クエリパラメータに関する置換はルールが単純なのでJSONでは定義せず、こちらのスクリプトで定義・処理している（# REMOVE QUERY PARAMETERのセクション）。  import pandas as pd import json  input_filename = \u0026#39;./input.csv\u0026#39; output_filename = \u0026#39;./output.csv\u0026#39;  input_csv = pd.read_csv(  input_filename,  sep=\u0026#39;,\u0026#39;,  usecols=lambda x: x in [\u0026#39;timestamp\u0026#39;,\u0026#39;alb_status_code\u0026#39;, \u0026#39;backend_status_code\u0026#39;, \u0026#39;method\u0026#39;, \u0026#39;URL\u0026#39;, \u0026#39;backend_processing_time_msec\u0026#39;],  index_col=\u0026#39;timestamp\u0026#39;,  dtype={\u0026#39;timestamp\u0026#39;: str, \u0026#39;alb_status_code\u0026#39;: str, \u0026#39;backend_status_code\u0026#39;: str, \u0026#39;method\u0026#39;: str, \u0026#39;URL\u0026#39;: str, \u0026#39;backend_processing_time_msec\u0026#39;: \u0026#39;float16\u0026#39;} )  # REMOVE QUERY PARAMETER input_csv = pd.","title":"JSONで定義したURLの置換ルールをPythonで変換する"},{"content":"  install 済みのパッケージ pip list\n  特定パッケージのインストール場所などの詳細情報 pip show jupyter\n  ","permalink":"https://ny1030.github.io/pages/posts/engineering/pip-commands/","summary":"  install 済みのパッケージ pip list\n  特定パッケージのインストール場所などの詳細情報 pip show jupyter\n  ","title":"pip Commands"},{"content":" apple というECRリポジトリの developタグの imageDigest を確認  aws ecr describe-images --repository-name apple --image-ids imageTag=develop | jq .imageDetails[].imageDigest  認証後にPull (AWSアカウントIDは12345678とする)  aws ecr get-login-password --region ap-northeast-1 | docker login --username AWS --password-stdin 12345678.dkr.ecr.ap-northeast-1.amazonaws.com TODO:\n スニペット化  ","permalink":"https://ny1030.github.io/pages/posts/engineering/aws-ecr-commands/","summary":" apple というECRリポジトリの developタグの imageDigest を確認  aws ecr describe-images --repository-name apple --image-ids imageTag=develop | jq .imageDetails[].imageDigest  認証後にPull (AWSアカウントIDは12345678とする)  aws ecr get-login-password --region ap-northeast-1 | docker login --username AWS --password-stdin 12345678.dkr.ecr.ap-northeast-1.amazonaws.com TODO:\n スニペット化  ","title":"AWS ECR Commands"},{"content":"一般用途  {USER_NAME } というユーザのオブジェクト権限確認  SELECT grantee, table_name, privilege FROM dba_tab_privs WHERE grantee = \u0026#39;USER_NAME\u0026#39;;  初期化パラメータの一覧  SELECT name,display_value,default_value,isdefault,description FROM V$PARAMETER;  隠しパラメータを調べる  select ksppinm as \u0026#34;parameter\u0026#34;, ksppstvl as \u0026#34;value\u0026#34; from x$ksppi join x$ksppcv using (indx) where ksppinm = \u0026#39;{隠しパラメータ名}\u0026#39;; 特定用途  気になるパラメータチェック  SELECT name,display_value,default_value,isdefault,description FROM V$PARAMETER WHERE name IN (\u0026#39;client_statistics_level\u0026#39;) OR name like \u0026#39;_optim%\u0026#39;;  気になる隠しパラメータ  select ksppinm as \u0026#34;parameter\u0026#34;, ksppstvl as \u0026#34;value\u0026#34; from x$ksppi join x$ksppcv using (indx) where ksppinm IN (\u0026#39;_optimizer_use_stats_on_conventional_dml\u0026#39;,\u0026#39;_optimizer_gather_stats_on_conventional_dml\u0026#39;); TODO:\n スニペット化  ","permalink":"https://ny1030.github.io/pages/posts/engineering/oracle-sqls/","summary":"一般用途  {USER_NAME } というユーザのオブジェクト権限確認  SELECT grantee, table_name, privilege FROM dba_tab_privs WHERE grantee = \u0026#39;USER_NAME\u0026#39;;  初期化パラメータの一覧  SELECT name,display_value,default_value,isdefault,description FROM V$PARAMETER;  隠しパラメータを調べる  select ksppinm as \u0026#34;parameter\u0026#34;, ksppstvl as \u0026#34;value\u0026#34; from x$ksppi join x$ksppcv using (indx) where ksppinm = \u0026#39;{隠しパラメータ名}\u0026#39;; 特定用途  気になるパラメータチェック  SELECT name,display_value,default_value,isdefault,description FROM V$PARAMETER WHERE name IN (\u0026#39;client_statistics_level\u0026#39;) OR name like \u0026#39;_optim%\u0026#39;;  気になる隠しパラメータ  select ksppinm as \u0026#34;parameter\u0026#34;, ksppstvl as \u0026#34;value\u0026#34; from x$ksppi join x$ksppcv using (indx) where ksppinm IN (\u0026#39;_optimizer_use_stats_on_conventional_dml\u0026#39;,\u0026#39;_optimizer_gather_stats_on_conventional_dml\u0026#39;); TODO:","title":"Oracle SQLs"},{"content":"やりたいこと  運用しているシステムで時折、CPU使用率が100%を超過しアクセス不可になる。 Compute Engine（GCE）のインスタンスを再起動することで上記事象は直るので、復旧時間を短くするために、通知することでできるだけ早く気付けるようにする。 通知先として、スマホから手軽に見れてWebhookで楽に設定できるDiscordを使ってみる。 通知のロジックを超カンタンな図で表すと以下のような形：   やったこと 通知ポリシーの作成（GCP管理画面） GCEのCPU使用率が95%以上の状態が何分間以上続いたら通知するか、といった条件をGCPの管理画面から設定する。これはGCEの画面のオブザーバビリティのタブから画像のように設定。 通知チャンネルの作成（GCP管理画面） 通知ポリシーと似た名前だがこちらは通知先を設定するサービス。画像の通りSlackやWebhook、（見えてないけど）SMSやEmailの設定が可能。今回はDiscordに通知したかったので通知したいDiscordチャンネルのWebhook URLを設定。 トラブルシューティング 上記の設定を終えたところで、通知チャンネルから「TEST CONNECTION」があったので試しに実行。 「successfully sent」と出ているがDiscordチャンネルを見るとメッセージが届いてない。。\nGCP側のログ確認 Cloud Logging で 確認したところ、同タイミングで400エラーが出ていることを確認 😇 curlで送ってみる 件のDiscordにcurlで試しにPOSTをしてみたところ、\n$ curl -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;data\u0026#34;: \u0026#34;Hello World\u0026#34;}\u0026#39; https://discord.com/api/webhooks/{YOUR_PATH} {\u0026#34;message\u0026#34;: \u0026#34;Cannot send an empty message\u0026#34;, \u0026#34;code\u0026#34;: 50006} というメッセージが返ってきた。status codeを調べると400なのでGCPと同じエラーっぽい。\n微修正して以下のようなPOSTをしたところ通知が成功。\n$ curl -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;content\u0026#34;: \u0026#34;Hello World\u0026#34;}\u0026#39; https://discord.com/api/webhooks/{YOUR_PATH} どうやらdiscordではJSONのpayloadに設定する key が \u0026ldquo;content\u0026rdquo; じゃないとエラーになる模様。なのでGCPではおそらく、content以外の key名を設定していてエラーが返ってきている？\n最終的にCloud Function で実装 以上のような経緯でWebhookで単純に送ることはできなかったため、同じような人がいないか調べたところ Cloud Functions で自前で作るのが良いとのこと。以下のような手順でCloud Functionsで実装を試してみた。\n Cloud Pub/Subのトピックを作成 通知チャンネルで通知先に Cloud Pub/Sub -\u0026gt; 上記トピックを選択 Cloud Functionsを作成  トリガーのタイプ：Cloud Pub/Sub ランタイム：Nodejs ソースは以下の通り    const { IncomingWebhook } = require(\u0026#39;@slack/webhook\u0026#39;); /** * Triggered from a message on a Cloud Pub/Sub topic. * * @param {!Object} event Event payload. * @param {!Object} context Metadata for the event. */ exports.notify = (event, context) =\u0026gt; { const message = event.data ? Buffer.from(event.data, \u0026#39;base64\u0026#39;).toString() : \u0026#39;Hello, World\u0026#39;; console.log(message); const body = { \u0026#34;content\u0026#34;: message }; // discordに通知 const webhook = new IncomingWebhook(\u0026#39;https://discord.com/api/webhooks/{YOUR_PATH}\u0026#39;); //await webhook.send(body); webhook.send(body); return \u0026#39;Discord notification sent successfully\u0026#39;; }; package.json\n{ \u0026#34;name\u0026#34;: \u0026#34;sample-pubsub\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;@google-cloud/pubsub\u0026#34;: \u0026#34;^0.18.0\u0026#34;, \u0026#34;@slack/webhook\u0026#34;: \u0026#34;^6.1.0\u0026#34; } } このFunctionをDeployして、再度テストしたところ無事に送信されたことを確認 ","permalink":"https://ny1030.github.io/pages/posts/engineering/gcp%E3%81%AE%E3%82%A2%E3%83%A9%E3%83%BC%E3%83%88%E6%83%85%E5%A0%B1%E3%82%92discord%E3%81%AB%E9%80%9A%E7%9F%A5%E3%81%99%E3%82%8B/","summary":"やりたいこと  運用しているシステムで時折、CPU使用率が100%を超過しアクセス不可になる。 Compute Engine（GCE）のインスタンスを再起動することで上記事象は直るので、復旧時間を短くするために、通知することでできるだけ早く気付けるようにする。 通知先として、スマホから手軽に見れてWebhookで楽に設定できるDiscordを使ってみる。 通知のロジックを超カンタンな図で表すと以下のような形：   やったこと 通知ポリシーの作成（GCP管理画面） GCEのCPU使用率が95%以上の状態が何分間以上続いたら通知するか、といった条件をGCPの管理画面から設定する。これはGCEの画面のオブザーバビリティのタブから画像のように設定。 通知チャンネルの作成（GCP管理画面） 通知ポリシーと似た名前だがこちらは通知先を設定するサービス。画像の通りSlackやWebhook、（見えてないけど）SMSやEmailの設定が可能。今回はDiscordに通知したかったので通知したいDiscordチャンネルのWebhook URLを設定。 トラブルシューティング 上記の設定を終えたところで、通知チャンネルから「TEST CONNECTION」があったので試しに実行。 「successfully sent」と出ているがDiscordチャンネルを見るとメッセージが届いてない。。\nGCP側のログ確認 Cloud Logging で 確認したところ、同タイミングで400エラーが出ていることを確認 😇 curlで送ってみる 件のDiscordにcurlで試しにPOSTをしてみたところ、\n$ curl -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;data\u0026#34;: \u0026#34;Hello World\u0026#34;}\u0026#39; https://discord.com/api/webhooks/{YOUR_PATH} {\u0026#34;message\u0026#34;: \u0026#34;Cannot send an empty message\u0026#34;, \u0026#34;code\u0026#34;: 50006} というメッセージが返ってきた。status codeを調べると400なのでGCPと同じエラーっぽい。\n微修正して以下のようなPOSTをしたところ通知が成功。\n$ curl -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;content\u0026#34;: \u0026#34;Hello World\u0026#34;}\u0026#39; https://discord.com/api/webhooks/{YOUR_PATH} どうやらdiscordではJSONのpayloadに設定する key が \u0026ldquo;content\u0026rdquo; じゃないとエラーになる模様。なのでGCPではおそらく、content以外の key名を設定していてエラーが返ってきている？\n最終的にCloud Function で実装 以上のような経緯でWebhookで単純に送ることはできなかったため、同じような人がいないか調べたところ Cloud Functions で自前で作るのが良いとのこと。以下のような手順でCloud Functionsで実装を試してみた。","title":"GCPのアラート情報をDiscordに通知する"},{"content":"こちら\n","permalink":"https://ny1030.github.io/pages/posts/engineering/webhook%E3%81%AE%E7%96%8E%E9%80%9A%E3%83%86%E3%82%B9%E3%83%88/","summary":"こちら","title":"Webhookの疎通テスト"},{"content":"from __future__ import print_function import pickle import os.path from googleapiclient.discovery import build from google_auth_oauthlib.flow import InstalledAppFlow from google.auth.transport.requests import Request # If modifying these scopes, delete the file token.pickle. SCOPES = [\u0026#39;https://www.googleapis.com/auth/drive.metadata.readonly\u0026#39;] def main(): \u0026#34;\u0026#34;\u0026#34;Shows basic usage of the Drive v3 API. Prints the names and ids of the first 10 files the user has access to. \u0026#34;\u0026#34;\u0026#34; creds = None # The file token.pickle stores the user\u0026#39;s access and refresh tokens, and is # created automatically when the authorization flow completes for the first # time. if os.path.exists(\u0026#39;token.pickle\u0026#39;): with open(\u0026#39;token.pickle\u0026#39;, \u0026#39;rb\u0026#39;) as token: creds = pickle.load(token) # If there are no (valid) credentials available, let the user log in. if not creds or not creds.valid: if creds and creds.expired and creds.refresh_token: creds.refresh(Request()) else: flow = InstalledAppFlow.from_client_secrets_file( \u0026#39;credentials.json\u0026#39;, SCOPES) creds = flow.run_local_server(port=0) # Save the credentials for the next run with open(\u0026#39;token.pickle\u0026#39;, \u0026#39;wb\u0026#39;) as token: pickle.dump(creds, token) service = build(\u0026#39;drive\u0026#39;, \u0026#39;v3\u0026#39;, credentials=creds) # Call the Drive v3 API results = service.files().list( pageSize=10, fields=\u0026#34;nextPageToken, files(id, name)\u0026#34;).execute() items = results.get(\u0026#39;files\u0026#39;, []) if not items: print(\u0026#39;No files found.\u0026#39;) else: print(\u0026#39;Files:\u0026#39;) for item in items: print(u\u0026#39;{0} ({1})\u0026#39;.format(item[\u0026#39;name\u0026#39;], item[\u0026#39;id\u0026#39;])) if __name__ == \u0026#39;__main__\u0026#39;: main() 参考サイト\n","permalink":"https://ny1030.github.io/pages/posts/engineering/google-drive%E3%81%AB%E3%81%82%E3%82%8B%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92ocr%E3%81%99%E3%82%8Bpython%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88/","summary":"from __future__ import print_function import pickle import os.path from googleapiclient.discovery import build from google_auth_oauthlib.flow import InstalledAppFlow from google.auth.transport.requests import Request # If modifying these scopes, delete the file token.pickle. SCOPES = [\u0026#39;https://www.googleapis.com/auth/drive.metadata.readonly\u0026#39;] def main(): \u0026#34;\u0026#34;\u0026#34;Shows basic usage of the Drive v3 API. Prints the names and ids of the first 10 files the user has access to. \u0026#34;\u0026#34;\u0026#34; creds = None # The file token.pickle stores the user\u0026#39;s access and refresh tokens, and is # created automatically when the authorization flow completes for the first # time.","title":"Google DriveにあるファイルをOCRするPythonスクリプト"},{"content":"freeコマンド  total : 合計 used : カーネルとプロセスが使用している shared : tmpfsに使われている free : 余っている buffers : バッファキャッシュのメモリサイズ cache : ページキャッシュのメモリサイズ available : 実質的な空きメモリ  free + buff/cache (解放可能な部分)     sar コマンド 物理メモリ使用量が表示される = buffers, cacheが含まれた使用量 sar -r でメモリ使用状況を確認する - ablog\n","permalink":"https://ny1030.github.io/pages/posts/engineering/linux-%E3%83%A1%E3%83%A2%E3%83%AA%E4%BD%BF%E7%94%A8%E7%8E%87%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/","summary":"freeコマンド  total : 合計 used : カーネルとプロセスが使用している shared : tmpfsに使われている free : 余っている buffers : バッファキャッシュのメモリサイズ cache : ページキャッシュのメモリサイズ available : 実質的な空きメモリ  free + buff/cache (解放可能な部分)     sar コマンド 物理メモリ使用量が表示される = buffers, cacheが含まれた使用量 sar -r でメモリ使用状況を確認する - ablog","title":"Linux - メモリ使用率について"},{"content":"ここではなくgistに記載\n","permalink":"https://ny1030.github.io/pages/posts/engineering/commandsnipet%E3%83%A1%E3%83%A2/","summary":"ここではなくgistに記載","title":"Command(Snipet)メモ"},{"content":"Level 0 実行計画(Query Plan)の読み方 以下のようなSQLの実行計画を取得してみる。\n UPDATE T_ITEM_INBOUND t3 SET status_flag = \u0026#39;9\u0026#39; , updated_datetime = CURRENT_TIMESTAMP , updated_by = \u0026#39;APP_001\u0026#39; FROM ( SELECT t1.group_num , t1.level3_item_code FROM T_ITEM_INBOUND t1 WHERE t1.status_flag = \u0026#39;1\u0026#39; AND t1.group_num = \u0026#39;10\u0026#39; AND t1.level3_item_code = \u0026#39;1000-2000-3000\u0026#39; GROUP BY t1.group_num , t1.level1_item_code , t1.level2_item_code , t1.level3_item_code , t1.color_code , t1.size_code , t1.pattern_length_code HAVING 1 \u0026lt; COUNT(t1.group_num) ) t2 WHERE t3.status_flag = \u0026#39;1\u0026#39; AND t3.group_num = t2.group_num AND t3.level3_item_code = t2.level3_item_code AND t3.brand_code = \u0026#39;TK\u0026#39; AND t3.region_code = \u0026#39;JP\u0026#39; 上記クエリの先頭に EXPLAIN ANALYZE というフレーズを付与→実行することで、以下のように実行計画が出力される。\n Update on T_ITEM_INBOUND t3 (cost=19152.43..40432.82 rows=1 width=299) (actual time=65.760..65.760 rows=0 loops=1) -\u0026gt; Hash Join (cost=19152.43..40432.82 rows=1 width=299) (actual time=65.758..65.758 rows=0 loops=1) Hash Cond: (((t3.group_num)::text = (t2.group_num)::text) AND (t3.level3_item_code = t2.level3_item_code)) -\u0026gt; Seq Scan on T_ITEM_INBOUND t3 (cost=0.00..19152.36 rows=283735 width=150) (actual time=4.019..4.019 rows=1 loops=1) Filter: (((status_flag)::text = \u0026#39;1\u0026#39;::text) AND (brand_code = \u0026#39;TK\u0026#39;::text) AND (region_code = \u0026#39;JP\u0026#39;::text)) Rows Removed by Filter: 11 -\u0026gt; Hash (cost=19152.42..19152.42 rows=1 width=62) (actual time=61.731..61.731 rows=0 loops=1) Buckets: 1024 Batches: 1 Memory Usage: 8kB -\u0026gt; Subquery Scan on t2 (cost=19152.37..19152.42 rows=1 width=62) (actual time=61.730..61.730 rows=0 loops=1) -\u0026gt; GroupAggregate (cost=19152.37..19152.41 rows=1 width=55) (actual time=61.730..61.730 rows=0 loops=1) Group Key: t1.group_num, t1.level1_item_code, t1.level2_item_code, t1.level3_item_code, t1.color_code, t1.size_code, t1.pattern_length_code Filter: (1 \u0026lt; count(t1.group_num)) Rows Removed by Filter: 1 -\u0026gt; Sort (cost=19152.37..19152.38 rows=1 width=55) (actual time=61.724..61.724 rows=1 loops=1) Sort Key: t1.level1_item_code, t1.level2_item_code, t1.color_code, t1.size_code, t1.pattern_length_code Sort Method: quicksort Memory: 25kB -\u0026gt; Seq Scan on T_ITEM_INBOUND t1 (cost=0.00..19152.36 rows=1 width=55) (actual time=21.804..61.714 rows=1 loops=1) Filter: (((status_flag)::text = \u0026#39;1\u0026#39;::text) AND ((group_num)::text = \u0026#39;10\u0026#39;::text) AND (l3_item_code = \u0026#39;1000-2000-3000\u0026#39;::text)) Rows Removed by Filter: 283734 全てを説明するのは長くなるので要点だけ。\nインデントは処理の順番を表す  処理を行う単位（=実行計画の各レコード）ノードと呼ぶ。 ノードはツリー構造で表現される。最下層のノード（=リーフノード）は必ずテーブルスキャンノードとなる。 最下層（=インデントが深い）のノードから順に実行される。 最下層ノードの親は結合ノードでさらにその親はその他のノードになっている。  テーブルスキャンノード テーブルからデータを取り出す役割。代表的なスキャン方法は以下の通り。\n Seq Scan: テーブル全体を順番にスキャンする Index Scan: テーブルに付与されているインデックスのみをスキャンし、実テーブルはスキャンしない  今回の例では Seq Scan が使われいている。\n結合系ノード 複数のテーブルを結合する役割のノードです。代表的な結合方法は以下の通り。\n Nested Loop: 外側テーブルの行毎に内側テーブルのすべての行を突き合わせ結合する Hash Join: 内側テーブルの結合キーでハッシュを作成し、ハッシュと外側テーブルの結合キーで一致する行を結合する  処理コスト 実行計画の各ノードには、始動コストと総コスト、行数と行の長さが記載されている。\n 始動コスト: 一件目のデータを返すのにかかる想定のコストを表す( .. の前) 総コスト: 処理完了までにかかる想定のコストを表す( .. の後) 行数： ノード実行によって返却される行数を表す( rows ) 行の長さ： ノードの実行によって返却される行の平均の長さを表す( width )  important  EXPLAIN のみをつけて実行計画を取得すると、プランナによって見積もられたコストとなる。 EXPLAIN ANALYZE をつけて実行計画を取得すると、実際に実行して得られた結果となる。( actual 以降の情報がそれ)  なので、 cost と actual の rows が大きくずれている場合は統計情報が古い可能性がある。\nLevel 1 Index利用による高速化 Level 2 部分Indexの利用 ","permalink":"https://ny1030.github.io/pages/posts/engineering/sql%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/","summary":"Level 0 実行計画(Query Plan)の読み方 以下のようなSQLの実行計画を取得してみる。\n UPDATE T_ITEM_INBOUND t3 SET status_flag = \u0026#39;9\u0026#39; , updated_datetime = CURRENT_TIMESTAMP , updated_by = \u0026#39;APP_001\u0026#39; FROM ( SELECT t1.group_num , t1.level3_item_code FROM T_ITEM_INBOUND t1 WHERE t1.status_flag = \u0026#39;1\u0026#39; AND t1.group_num = \u0026#39;10\u0026#39; AND t1.level3_item_code = \u0026#39;1000-2000-3000\u0026#39; GROUP BY t1.group_num , t1.level1_item_code , t1.level2_item_code , t1.level3_item_code , t1.color_code , t1.size_code , t1.pattern_length_code HAVING 1 \u0026lt; COUNT(t1.group_num) ) t2 WHERE t3.status_flag = \u0026#39;1\u0026#39; AND t3.group_num = t2.","title":"SQLパフォーマンスチューニング"},{"content":"サービス再起動 bitnami drupal の場合 sudo /opt/bitnami/ctlscript.sh restart マイナーバージョンアップ ※スペック低すぎると失敗するので、4コア8GBに事前スケールアップした\n バージョン確認  composer outdated \u0026quot;drupal/*\u0026quot;\n druplaのrootディレクトリで以下を実行  sudo composer update drupal/core \u0026quot;drupal/core-*\u0026quot; --with-all-dependencies sudo composer update drupal/core --with-dependencies\n参考\nhousekeeping(キャッシュ削除) drush -y wd-del all\nリダイレクト設定 こちらの通りに設定 installdir/apache2/conf/vhosts/APPNAME-vhost.conf に設定を書けば良い\n","permalink":"https://ny1030.github.io/pages/posts/engineering/drupal%E9%96%A2%E9%80%A3%E3%81%AE%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89/","summary":"サービス再起動 bitnami drupal の場合 sudo /opt/bitnami/ctlscript.sh restart マイナーバージョンアップ ※スペック低すぎると失敗するので、4コア8GBに事前スケールアップした\n バージョン確認  composer outdated \u0026quot;drupal/*\u0026quot;\n druplaのrootディレクトリで以下を実行  sudo composer update drupal/core \u0026quot;drupal/core-*\u0026quot; --with-all-dependencies sudo composer update drupal/core --with-dependencies\n参考\nhousekeeping(キャッシュ削除) drush -y wd-del all\nリダイレクト設定 こちらの通りに設定 installdir/apache2/conf/vhosts/APPNAME-vhost.conf に設定を書けば良い","title":"Drupal関連のコマンド"},{"content":"※ OSは Ubuntu 20.04(LTS) を使用\n まずはプロンプトを変更（ミニマルな内容にする）  #1.まずは現在の設定確認 user@DESKTOP-XXXXX:~$ **echo $PS1** \\\\[\\\\e]0;\\\\u@\\\\h: \\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[00m\\\\]\\\\$ #2.PS1の値を書き換え user@DESKTOP-XXXXX:~$ **PS1=\u0026#39;\\\\[\\\\e[1;32m\\\\]\\\\W\\\\$ \\\\[\\\\e[m\\\\]\u0026#39;** ~$ #3.設定内容を永続化 ~$ **echo \u0026#34;PS1=\u0026#39;\\\\[\\\\e[1;32m\\\\]\\\\W\\\\$ \\\\[\\\\e[m\\\\]\u0026#39;\u0026#34; \u0026gt;\u0026gt; .bashrc** #4.ターミナルを再起動して、設定が永続化されてること確認 ~$  systemd を PID1（親プロセス）にする  #1.現状のプロセスを確認 ~$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 896 528 ? Sl 16:13 0:00 /init root 120 0.0 0.0 896 84 ? Ss 16:19 0:00 /init #2.dotnet-runtime-5.0などの依存モジュールをインストール wget \u0026lt;https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb\u0026gt; -O packages-microsoft-prod.deb sudo dpkg -i packages-microsoft-prod.deb rm packages-microsoft-prod.deb sudo apt-get update; \\\\ sudo apt-get install -y apt-transport-https \u0026amp;\u0026amp; \\\\ sudo apt-get update \u0026amp;\u0026amp; \\\\ sudo apt-get install -y aspnetcore-runtime-5.0 sudo apt install -y daemonize dbus gawk libc6 libstdc++6 policykit-1 systemd systemd-container sudo -s apt install apt-transport-https wget -O /etc/apt/trusted.gpg.d/wsl-transdebian.gpg \u0026lt;https://arkane-systems.github.io/wsl-transdebian/apt/wsl-transdebian.gpg\u0026gt; chmod a+r /etc/apt/trusted.gpg.d/wsl-transdebian.gpg cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list.d/wsl-transdebian.list deb \u0026lt;https://arkane-systems.github.io/wsl-transdebian/apt/\u0026gt; $(lsb_release -cs) main deb-src \u0026lt;https://arkane-systems.github.io/wsl-transdebian/apt/\u0026gt; $(lsb_release -cs) main EOF apt update #3.genieインストール sudo apt install -y systemd-genie #4.genieを実行 genie -s #5.エラー解消 #5-1.systemd-remount-fs.serviceのエラーを解消する dfでルートパーティション確認→/dev/sdb sudo e2label /dev/sdb cloudimg-rootfs #5-2.multipathd.socketのエラーを解消する sudo systemctl disable multipathd.socket #5-3.ssh.serviceのエラーを解消する sudo ssh-keygen -A #6.bashrcに設定記入 # Are we in the bottle? if [[ ! -v INSIDE_GENIE ]]; then echo \u0026#34;Starting genie:\u0026#34; exec /usr/bin/genie -s fi #7.Ubuntu再起動後にPID1を確認 ~$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.2 0.1 175028 13128 ? Ss 21:40 0:01 systemd root 50 0.0 0.1 51456 15596 ? S\u0026lt;s 21:40 0:00 /lib/systemd/systemd-journald root 72 0.0 0.0 19564 5228 ? Ss 21:40 0:00 /lib/systemd/systemd-udevd 補足：systemdをPID1にしないと、systemctlを実行すると以下のようなエラーが出る\nSystem has not been booted with systemd as init system (PID 1). Can\u0026#39;t operate. Failed to connect to bus: Host is down  WindowsのPATHを引き継がないように設定  1. 設定の追加 sudo vi /etc/wsl.conf -- # WindowsのPATHを引き継がない設定を追記する [interop] appendWindowsPath = false 2. Widnowsコマンドプロンプトから再起動 -- wsl.exe --shutdown  Golangをインストール  # 1. Goのパッケージをダウンロード ~$ wget \u0026lt;https://go.dev/dl/go1.17.7.linux-amd64.tar.gz\u0026gt; # 2. 展開 ~$ sudo tar -C /usr/local -xzf go1.17.7.linux-amd64.tar.gz # 3. PATHに追加・反映 ~$ echo \u0026#34;PATH=$PATH:/usr/local/go/bin\u0026#34; \u0026gt;\u0026gt; .bashrc ~$ source .bashrc # 4．動作確認 ~$ go version go version go1.17.7 linux/amd64  ghq（Gitリポジトリ管理ツール）をインストール  go install github.com/x-motemen/ghq@latest echo \u0026#34;PATH=$PATH:~/go/bin\u0026#34; \u0026gt;\u0026gt; .bashrc # dial tcp: lookup proxy.golang.org: no such host のエラー出た場合 go env -w GOPROXY=direct  AWS CLI 2をインストール  curl \u0026#34;\u0026lt;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026gt;\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install ~$ aws --version aws-cli/2.4.23 Python/3.8.8 Linux/5.10.60.1-microsoft-standard-WSL2 exe/x86_64.ubuntu.20 prompt/off  AWS Session Managerをインストール  curl \u0026#34;\u0026lt;https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb\u0026gt;\u0026#34; -o \u0026#34;session-manager-plugin.deb\u0026#34; sudo dpkg -i session-manager-plugin.deb ~$ session-manager-plugin The Session Manager plugin was installed successfully. Use the AWS CLI to start a session. Proxy環境下の関連設定 zscalerの場合  Linuxで証明書導入  /usr/share/ca-certificates/ 配下に任意のディレクトリ作成 /usr/share/ca-certificates/zscaler/ 配下に証明書を配置 /etc/ca-certificates.confに/usr/share/ca-certificates/ 以下の相対パスを追加 （ここではzscaler/zscaler.cer） /usr/sbin/update-ca-certificatesを実行  aws  export AWS_CA_BUNDLE=~/zscaler_root.crt  git, conda, pip  １．最新のPythonの信頼する証明書リストを入手する。\u0026lt;https://curl.haxx.se/ca/cacert.pemからダウンロードする。\u0026gt; ２．このファイルの末尾に、テキスト形式で保存したzscalerのオレオレ証明書のテキストを追加する。 ３．以下のパスに保存する# Windows%USERPROFILE%\\\\certs\\\\ca-bundle.crt ４．以下のコマンドをコマンドプロンプトで実行し、保存した証明書リストを使うように設定する。 pip config set global.cert %USERPROFILE%\\\\certs\\\\ca-bundle.crtconda config --set ssl_verify %USERPROFILE%\\\\certs\\\\ca-bundle.crtgit config --global http.sslVerify truegit config --global http.sslCAInfo path/to/ca-bundle.crt  DNS Resolver に8.8.8.8追加  #1. /etc/systemd/resolved.conf に以下を追加 --------------- [Resolve] DNS=8.8.8.8 #2.再起動 systemctl restart systemd-resolved #3.DNS確認 systemd-resolve --status ","permalink":"https://ny1030.github.io/pages/posts/engineering/wsl2%E3%82%92%E5%85%A5%E3%82%8C%E3%81%9F%E5%BE%8C%E3%81%AB%E3%82%84%E3%82%8B%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%9E%E3%82%A4%E3%82%BA/","summary":"※ OSは Ubuntu 20.04(LTS) を使用\n まずはプロンプトを変更（ミニマルな内容にする）  #1.まずは現在の設定確認 user@DESKTOP-XXXXX:~$ **echo $PS1** \\\\[\\\\e]0;\\\\u@\\\\h: \\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[00m\\\\]\\\\$ #2.PS1の値を書き換え user@DESKTOP-XXXXX:~$ **PS1=\u0026#39;\\\\[\\\\e[1;32m\\\\]\\\\W\\\\$ \\\\[\\\\e[m\\\\]\u0026#39;** ~$ #3.設定内容を永続化 ~$ **echo \u0026#34;PS1=\u0026#39;\\\\[\\\\e[1;32m\\\\]\\\\W\\\\$ \\\\[\\\\e[m\\\\]\u0026#39;\u0026#34; \u0026gt;\u0026gt; .bashrc** #4.ターミナルを再起動して、設定が永続化されてること確認 ~$  systemd を PID1（親プロセス）にする  #1.現状のプロセスを確認 ~$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 896 528 ? Sl 16:13 0:00 /init root 120 0.0 0.0 896 84 ? Ss 16:19 0:00 /init #2.","title":"WSL2を入れた後にやるカスタマイズ"},{"content":"１．環境セットアップ（２時間くらい） Flutter １．SDKのダウンロード・解凍\nInstall\n２．PATH設定\n以下をPATHに追加（ホームディレクトリの名前は適宜変更する）\n/Users/{username}/flutter/bin ３．確認\n以下のコマンドが実行できることを確認する\nflutter Android １．Android Studioダウンロード⇛インストール\nInstall\n２．確認\nflutter doctor ※最初は５分くらい時間かかる\nの結果でAndroid Studioがチェックマーク入ってるのを確認 ![[Pasted image 20220513215817.png]]\n４．Andoroid toolchainのエラー解消\n・Command-Line Toolsのインストール（AndoroidSDKの設定画面からできる）\n![[Pasted image 20220513215852.png]]\n・Andoroidライセンスの許可\nflutter doctor --android-licenses ※ javaのPATH通ってないとエラー出る\n５．Android toolchainがチェックついてることを確認\nflutter doctor ![[Pasted image 20220513215916.png]]\n６．FlutterプラグインをAndoroid Studioからインストール\n![[Pasted image 20220513215944.png]]\nXCode（iOS） １．XCodeをインストール\n２．Cocoapodをインストール\nbrew install cocoapods brew link --overwrite cocoapods ※バージョン指定している理由はエラー回避しようとした結果\n３．XCodeにチェックがついてることを確認\nflutter doctor ![[Pasted image 20220513220013.png]]\n２．Flutterプロジェクト作成・デモアプリ実行（30分） １．以下のように作成\n![[Pasted image 20220513220039.png]]\n２．仮想デバイス（iOS）を実装\n![[Pasted image 20220513220108.png]] ![[Pasted image 20220513220127.png]]\n３．仮想デバイス（Andoroid）を実装 ![[Pasted image 20220513220156.png]] ![[Pasted image 20220513220209.png]]\nSystem Image：何でもいいらしいのでPieに ![[Pasted image 20220513220235.png]] ![[Pasted image 20220513220251.png]]\n４．アプリの実行 ![[Pasted image 20220513220307.png]] Android： ![[Pasted image 20220513220324.png]]\niOS：同じ見た目 ![[Pasted image 20220513220346.png]]\nAppendix．UIのデザインツール ３−１．Flutter Studio\nWEB上でデザイン⇛コード生成できるが、\n・慣れが必要そう、機能的にFigmaに劣ってそう\n・コードを完全には使えない（クラス名がデフォルト、構文？が違う）\nAppBuilder 2 20180529-19:35\n３−２．Figma to Flutter\n・生成されるコードがイマイチ\nFigma to Flutter\n３−３．Adobe XD\nこれは使ってないが、一番マシな気がする。ただし有償\n","permalink":"https://ny1030.github.io/pages/posts/engineering/flutter-%E5%B0%8E%E5%85%A5%E3%81%BE%E3%81%A8%E3%82%81/","summary":"１．環境セットアップ（２時間くらい） Flutter １．SDKのダウンロード・解凍\nInstall\n２．PATH設定\n以下をPATHに追加（ホームディレクトリの名前は適宜変更する）\n/Users/{username}/flutter/bin ３．確認\n以下のコマンドが実行できることを確認する\nflutter Android １．Android Studioダウンロード⇛インストール\nInstall\n２．確認\nflutter doctor ※最初は５分くらい時間かかる\nの結果でAndroid Studioがチェックマーク入ってるのを確認 ![[Pasted image 20220513215817.png]]\n４．Andoroid toolchainのエラー解消\n・Command-Line Toolsのインストール（AndoroidSDKの設定画面からできる）\n![[Pasted image 20220513215852.png]]\n・Andoroidライセンスの許可\nflutter doctor --android-licenses ※ javaのPATH通ってないとエラー出る\n５．Android toolchainがチェックついてることを確認\nflutter doctor ![[Pasted image 20220513215916.png]]\n６．FlutterプラグインをAndoroid Studioからインストール\n![[Pasted image 20220513215944.png]]\nXCode（iOS） １．XCodeをインストール\n２．Cocoapodをインストール\nbrew install cocoapods brew link --overwrite cocoapods ※バージョン指定している理由はエラー回避しようとした結果\n３．XCodeにチェックがついてることを確認\nflutter doctor ![[Pasted image 20220513220013.png]]\n２．Flutterプロジェクト作成・デモアプリ実行（30分） １．以下のように作成\n![[Pasted image 20220513220039.png]]","title":"Flutter 導入まとめ"}]